---
layout: post
title:  "Gradient Boosting Forest: a Two-Stage Ensemble Method Enabling Federated Learning of GBDTs"
date:   2021-11-01 21:21:53 +00:00
image: /images/thumbnail_02.png
categories: ICONIP
venue: "International Conference on Neural Information Processing (ICONIP2021)"
author: "Feng Wang"
authors: "<strong>Feng Wang</strong>, Jinxiang Ou, Hairong Lv"
pdf: https://link.springer.com/chapter/10.1007/978-3-030-92270-2_7
---
We propose a novel tree-boosting method, called Gradient Boosting Forest (GBF), where the single decision tree in each gradient boosting round of GBDT is replaced by a set of trees trained from different subsets of the training data (referred to as a forest) which enables training GBDT with decentralized data. We empirically prove that GBF outperforms the existing GBDT methods in both centralized (GBF-Cen) and federated (GBF-Fed) cases.
